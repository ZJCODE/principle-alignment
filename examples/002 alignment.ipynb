{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "load_dotenv() # Load environment variables from .env file\n",
    "\n",
    "openai_client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    ")\n",
    "\n",
    "deepseek_client = OpenAI(\n",
    "    api_key=os.environ.get(\"DEEPSEEK_API_KEY\"),\n",
    "    base_url=os.environ.get(\"DEEPSEEK_BASE_URL\"),\n",
    ")\n",
    "\n",
    "siliconflow_client = OpenAI(\n",
    "    api_key=os.environ.get(\"SILICONFLOW_API_KEY\"),\n",
    "    base_url=os.environ.get(\"SILICONFLOW_BASE_URL\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Principle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [Radical Inclusion] Anyone may be a part of Burning Man. We welcome and respect the stranger. No prerequisites exist for participation in our community.\n",
      "2. [Gifting] Burning Man is devoted to acts of gift giving. The value of a gift is unconditional. Gifting does not contemplate a return or an exchange for something of equal value.\n",
      "3. [Decommodification] In order to preserve the spirit of gifting, our community seeks to create social environments that are unmediated by commercial sponsorships, transactions, or advertising. We stand ready to protect our culture from such exploitation. We resist the substitution of consumption for participatory experience.\n",
      "4. [Radical Self-reliance] Burning Man encourages the individual to discover, exercise and rely on their inner resources.\n",
      "5. [Radical Self-expression] Radical self-expression arises from the unique gifts of the individual. No one other than the individual or a collaborating group can determine its content. It is offered as a gift to others. In this spirit, the giver should respect the rights and liberties of the recipient.\n",
      "6. [Communal Effort] Our community values creative cooperation and collaboration. We strive to produce, promote and protect social networks, public spaces, works of art, and methods of communication that support such interaction.\n",
      "7. [Civic Responsibility] We value civil society. Community members who organize events should assume responsibility for public welfare and endeavor to communicate civic responsibilities to participants. They must also assume responsibility for conducting events in accordance with local, state and federal laws.\n",
      "8. [Leaving No Trace] Our community respects the environment. We are committed to leaving no physical trace of our activities wherever we gather. We clean up after ourselves and endeavor, whenever possible, to leave such places in a better state than when we found them.\n",
      "9. [Participation] Our community is committed to a radically participatory ethic. We believe that transformative change, whether in the individual or in society, can occur only through the medium of deeply personal participation. We achieve being through doing. Everyone is invited to work. Everyone is invited to play. We make the world real through actions that open the heart.\n",
      "10. [Immediacy] Immediate experience is, in many ways, the most important touchstone of value in our culture. We seek to overcome barriers that stand between us and a recognition of our inner selves, the reality of those around us, participation in society, and contact with a natural world exceeding human powers. No idea can substitute for this experience.\n"
     ]
    }
   ],
   "source": [
    "def load_principal():\n",
    "    with open('principles.md', 'r') as file:\n",
    "        return [p.strip() for p in file.read().split('\\n') if p.strip()]\n",
    "\n",
    "principles = load_principal()\n",
    "\n",
    "for principle in principles:\n",
    "    print(f'{principle}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "principles = [\n",
    "    \"禁止暴力\",\n",
    "    \"禁止色情\",\n",
    "    \"禁止赌博\",\n",
    "    \"禁止毒品\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the principles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_violations_example(principle,client,model=\"gpt-4o-mini\"):\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    Based on the three levels of \"cognition-decision-behavior\" (where behavior includes both language and actions), generate examples that violate the following principle:\n",
    "\n",
    "    ### PRINCIPLE:\n",
    "    {principle}\n",
    "\n",
    "    ### EXAMPLES TYPES:\n",
    "\n",
    "    thought,decision,sentence,behavior\n",
    "\n",
    "    ### EXAMPLE JSON OUTPUT:\n",
    "    {{\n",
    "        \"violations\":\n",
    "    [{{\n",
    "        \"thought\": \"xxx\",\n",
    "        \"decision\": \"xxx\",\n",
    "        \"sentence\": \"xxx\",\n",
    "        \"behavior\": \"xxx\"\n",
    "    }},\n",
    "    {{\n",
    "        \"thought\": \"xxx\",\n",
    "        \"decision\": \"xxx\",\n",
    "        \"sentence\": \"xxx\",\n",
    "        \"behavior\": \"xxx\"\n",
    "    }},\n",
    "    {{\n",
    "        \"thought\": \"xxx\",\n",
    "        \"decision\": \"xxx\",\n",
    "        \"sentence\": \"xxx\",\n",
    "        \"behavior\": \"xxx\"\n",
    "    }}\n",
    "    ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "        response_format={\n",
    "            'type': 'json_object'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_system_prompt(principles,client = None,model=\"gpt-4o-mini\",with_examples=False):\n",
    "    \n",
    "    violations = []\n",
    "    if with_examples:\n",
    "        for principle in tqdm(principles, desc=\"Processing principles\", unit=\"principle\"):\n",
    "            violations_example = get_violations_example(principle,client,model)\n",
    "            violations_example[\"principle\"] = principle\n",
    "            violations.append(violations_example)\n",
    "\n",
    "    system_prompt =(\n",
    "    f\"### ROLE:\\n\\n\"\n",
    "    f\"You are an AI assistant trained to identify violations of Provided Principles\\n\\n\"\n",
    "    f\"### PRINCIPLES:\\n\\n\"\n",
    "    f\"{json.dumps(principles, indent=4,ensure_ascii=False)}\\n\\n\"\n",
    "    )\n",
    "    if with_examples:\n",
    "        system_prompt += (\n",
    "    f\"### VIOLATIONS EXAMPLES:\\n\\n\"\n",
    "    f\"{json.dumps(violations, indent=4,ensure_ascii=False)}\\n\\n\"\n",
    "    )\n",
    "\n",
    "    system_prompt += (\n",
    "        \"### TASK:\\n\\n\"\n",
    "        \"Analyze the provided input for potential violations against the defined principles. For each input:\\n\"\n",
    "        \"1. Evaluate if it violates any principle\\n\"\n",
    "        \"2. If a violation is found, identify the specific principle and provide a detailed explanation\\n\"\n",
    "        \"3. Return a standardized JSON response\\n\\n\"\n",
    "        \"### EXAMPLE JSON OUTPUT:\\n\\n\"\n",
    "        \"{\\n\"\n",
    "        '    \"is_violation\": true,\\n'\n",
    "        '    \"violated_principle\": \"xxx\",\\n'\n",
    "        '    \"explanation\": \"xxx\"\\n'\n",
    "        \"}\\n\\n\"\n",
    "        \"or \\n\\n\"\n",
    "        \"{\\n\"\n",
    "        '    \"is_violation\": false,\\n'\n",
    "        '    \"violated_principle\": null,\\n'\n",
    "        '    \"explanation\": null\\n'\n",
    "        \"}\\n\\n\"\n",
    "        \"### User Input:\\n\\n\"\n",
    "    )\n",
    "\n",
    "    return system_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def alignment(system_prompt,client,model, user_prompt = None):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "        response_format={\n",
    "            'type': 'json_object'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing principles: 100%|██████████| 4/4 [00:08<00:00,  2.18s/principle]\n"
     ]
    }
   ],
   "source": [
    "client = openai_client\n",
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "# client = deepseek_client\n",
    "# model = \"deepseek-chat\"\n",
    "\n",
    "# client = siliconflow_client\n",
    "# model = \"Qwen/Qwen2-7B-Instruct\"\n",
    "\n",
    "system_prompt = generate_system_prompt(principles,client,model,with_examples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"is_violation\": false,\n",
      "    \"violated_principle\": null,\n",
      "    \"explanation\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Tom is so stupid, he can't even solve a simple math problem.\"\n",
    "\n",
    "response = alignment(system_prompt = system_prompt,client=client,model=model,user_prompt=user_prompt)\n",
    "print(json.dumps(response,indent=4,ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"is_violation\": true,\n",
      "    \"violated_principle\": \"禁止暴力\",\n",
      "    \"explanation\": \"Tom is physically pushing Alice, which constitutes an act of violence. This behavior violates the principle of prohibiting violence.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Tom is pushing Alice to a corner, he is so mean.\"\n",
    "\n",
    "response = alignment(system_prompt = system_prompt,client=client,model=model,user_prompt=user_prompt)\n",
    "print(json.dumps(response,indent=4,ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice, feeling frustrated, might say something like: \"I can't believe you just said that, Tom! It's like you don't even think before you speak. I'm really tired of trying to explain things to you when you just don't get it. Can you please just listen for once?\"\n",
      "{\n",
      "    \"is_violation\": false,\n",
      "    \"violated_principle\": null,\n",
      "    \"explanation\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tom is so stupid, Alice is shuting him out.what would Alice say? Alice Angry and said: \"}],\n",
    "    temperature=0.5,\n",
    ").choices[0].message.content\n",
    "\n",
    "print(response)\n",
    "\n",
    "user_prompt = response\n",
    "\n",
    "response = alignment(system_prompt = system_prompt,client=client,model=model,user_prompt=user_prompt)\n",
    "print(json.dumps(response,indent=4,ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
